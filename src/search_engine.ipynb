{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf89179",
   "metadata": {},
   "source": [
    "### Setup Elasticsearch cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bca8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "get_ipython().system = os.system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b72876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download Elasticsearch binaries into downloads folder\n",
    "# <YOUR PASSWORD> is your sudo password\n",
    "!mkdir ../downloads\n",
    "!wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz -P ../downloads\n",
    "!wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512 -P ../downloads\n",
    "!tar -xzf ../downloads/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz -C ../downloads\n",
    "!echo \"<YOUR PASSWORD>\" | sudo chown -R daemon:daemon ../downloads/elasticsearch-7.9.2/\n",
    "!shasum -a 512 -c ../downloads/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Elasticsearch server as bg process\n",
    "!echo \"<YOUR PASSWORD>\" | sudo -HSu daemon ../downloads/elasticsearch-7.9.2/bin/elasticsearch &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01c122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the daemon process status\n",
    "!!ps -ef | grep elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec1dc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = 9200\n",
    "host = f'http://localhost:{port}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the cluster started up correctly\n",
    "time.sleep(30)\n",
    "!!curl -s {host}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6641c",
   "metadata": {},
   "source": [
    "## Collect browser history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca8c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import os\n",
    "import glob\n",
    "import platform\n",
    "import shutil\n",
    "import tempfile\n",
    "import sqlite3\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d79912",
   "metadata": {},
   "source": [
    "#### Base aggregator\n",
    "Every browser implements the base class as except-chromimum based ones they differ in implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57460a5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Aggregator:\n",
    "    def __init__(self):\n",
    "        self.browsing_history = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        # scan browsers internal history dbs\n",
    "        curr_os = platform.system()\n",
    "        home_dir = path.expanduser('~')\n",
    "        oss_bin_paths = {\n",
    "            'Linux'  : ('/', 'usr', 'bin'),\n",
    "            'Darwin' : ('/', 'Applications'),\n",
    "            'Windows': ('C:/', 'Program Files')\n",
    "        }\n",
    "        # /usr/bin: symlinked from /usr/lib\n",
    "        install_dirs = {\n",
    "            os : path.join(*path_comps) \n",
    "            for os, path_comps in oss_bin_paths.items()\n",
    "        }\n",
    "        browsers_data_stores = {\n",
    "            'Chrome' : ('.config', 'google-chrome', 'Default', 'History'),\n",
    "            'Firefox' : ('.mozilla', 'firefox', '*.default', 'places.sqlite')\n",
    "        }\n",
    "        browsers = {\n",
    "            browser : path.join(home_dir, *path_comps) \n",
    "            for browser, path_comps in browsers_data_stores.items()\n",
    "        }        \n",
    "        # store both locked and lock-free db copies\n",
    "        self.db_files = {\n",
    "            browser : {\n",
    "                file_t : {} for file_t in ['orig', 'tmp']\n",
    "            }\n",
    "            for browser in browsers\n",
    "        }\n",
    "        \n",
    "        for browser in browsers:\n",
    "            found = glob.glob(f'{install_dirs[curr_os]}/*{browser.lower()}*') is not None\n",
    "            if found:\n",
    "                orig_file = glob.glob(browsers[browser])\n",
    "                tmp_file = self._tmp_copy(*orig_file)\n",
    "                self.db_files[browser]['orig'] = orig_file\n",
    "                self.db_files[browser]['tmp'] = tmp_file\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        # delete tmp copies on exit\n",
    "        for _, files in self.db_files.items():\n",
    "            os.remove(files['tmp'])\n",
    "                    \n",
    "    def _tmp_copy(self, original_file):\n",
    "        tmp = tempfile.gettempdir()\n",
    "        filename = path.basename(original_file)\n",
    "        tmp_file = path.join(tmp, filename)\n",
    "        shutil.copy2(original_file, tmp_file)\n",
    "        return tmp_file\n",
    "        \n",
    "    @classmethod\n",
    "    def _regexp(cls, regex, field_val):\n",
    "        # base REGEXP implementation\n",
    "        return bool(re.search(regex, field_val))\n",
    "    \n",
    "    def _extract(self, row):\n",
    "        return row[0]\n",
    "    \n",
    "    def _get_history_tables(self, conn, cursor):\n",
    "        conn.create_function(\"REGEXP\", 2, Aggregator._regexp)\n",
    "        regex = '.*(history|visit).*'\n",
    "        query = cursor.execute(\"\"\"\n",
    "            SELECT name FROM sqlite_master \n",
    "            WHERE type=\"table\" and name REGEXP ?\n",
    "        \"\"\", [regex])\n",
    "        rows = query.fetchall()\n",
    "        rows = [*map(self._extract, rows)]\n",
    "        return rows\n",
    "   \n",
    "    def _get_fields(self, table):\n",
    "        # looksup a table's columns\n",
    "        query = self.cursor.execute(f'SELECT * FROM {table}')\n",
    "        fields = [*map(self._extract, query.description)]\n",
    "        return fields\n",
    "            \n",
    "    def _to_dict(self, row, fields):\n",
    "        # converts row to dict by mapping columns to values\n",
    "        dict_ = {}\n",
    "        for i, val in enumerate(row):\n",
    "            field = self._extract(fields[i])\n",
    "            if field == 'visit_type':\n",
    "                val = self._visit_type(val)\n",
    "                val = val.split('_')[-1].lower()\n",
    "            dict_[field] = val\n",
    "        return dict_\n",
    "    \n",
    "    def _to_json(self, cursor):\n",
    "        fields = cursor.description\n",
    "        rows = cursor.fetchall()\n",
    "        rows = [ self._to_dict(row, fields) for row in rows ]\n",
    "        # rows_as_json = json.dumps(rows, indent = 2)\n",
    "        return rows\n",
    "    \n",
    "    def merge(self, history):\n",
    "        if not self.browsing_history:\n",
    "            self.browsing_history = history\n",
    "        else:\n",
    "            self.browsing_history += history\n",
    "                                 \n",
    "    def get_history_as_json(self):\n",
    "        # returns browser history as list of json documents\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def save(self):\n",
    "        if self.browsing_history:\n",
    "            file_path = os.path.join('../dataset', 'browsing_history.json')\n",
    "            with open(file_path, 'w') as file:\n",
    "                json.dump(self.browsing_history, file, indent = 2)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b3f848",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class AggregatorFirefox(Aggregator):\n",
    "    def __init__(self, db_file):\n",
    "        # raises sqlite3.OperationalError: unable to open database file\n",
    "        self.conn = sqlite3.connect(f'file:{db_file}?mode=ro', uri = True)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        sqlite3.enable_callback_tracebacks(True)\n",
    "            \n",
    "    def _visit_type(self, enum):\n",
    "        # maps visit types to their written rep for ease of querying\n",
    "        return [\n",
    "            'TRANSITION_LINK',\n",
    "            'TRANSITION_TYPED',\n",
    "            'TRANSITION_BOOKMARK',\n",
    "            'TRANSITION_EMBED',\n",
    "            'TRANSITION_REDIRECT_PERMANENT',\n",
    "            'TRANSITION_REDIRECT_TEMPORARY',\n",
    "            'TRANSITION_DOWNLOAD',\n",
    "            'TRANSITION_FRAMED_LINK',\n",
    "            'TRANSITION_RELOAD'\n",
    "        ][enum - 1]\n",
    "\n",
    "    def get_history_as_json(self):\n",
    "        # returns browser history as list of json documents\n",
    "        self.cursor.execute(\"\"\"\n",
    "            SELECT moz_historyvisits.id,\n",
    "                   moz_places.url, \n",
    "                   moz_places.title, \n",
    "                   moz_places.visit_count,\n",
    "                   (\n",
    "                       SELECT printf(\"%d\", total(use_count))\n",
    "                       FROM moz_inputhistory \n",
    "                       WHERE moz_inputhistory.place_id = moz_places.id\n",
    "                   ) typed_count,\n",
    "                   DATETIME(moz_places.last_visit_date/1000000,'unixepoch') as last_visit_date, \n",
    "                   DATETIME(moz_historyvisits.visit_date/1000000, 'unixepoch') as visit_date, \n",
    "                   moz_historyvisits.from_visit,\n",
    "                   moz_historyvisits.visit_type,\n",
    "                   'Firefox' as browser\n",
    "            FROM moz_places, moz_historyvisits \n",
    "            WHERE moz_historyvisits.place_id = moz_places.id;\n",
    "        \"\"\")\n",
    "        rows_as_json = self._to_json(self.cursor)\n",
    "        return rows_as_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcc370",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class AggregatorChrome(Aggregator):\n",
    "    def __init__(self, db_file):\n",
    "        # raises sqlite3.OperationalError: unable to open database file\n",
    "        self.conn = sqlite3.connect(f'file:{db_file}?mode=ro', uri = True)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        sqlite3.enable_callback_tracebacks(True)\n",
    "         \n",
    "    def _visit_type(self, enum):\n",
    "        # maps visit types to their written rep for ease of querying\n",
    "        CORE_MASK = 0xFF\n",
    "        return [\n",
    "            'LINK',\n",
    "            'TYPED',\n",
    "            'AUTO_BOOKMARK',\n",
    "            'AUTO_SUBFRAME',\n",
    "            'MANUAL_SUBFRAME',\n",
    "            'GENERATED',\n",
    "            'START_PAGE',\n",
    "            'FORM_SUBMIT',\n",
    "            'RELOAD',\n",
    "            'KEYWORD',\n",
    "            'KEYWORD_GENERATED'\n",
    "        ][enum & CORE_MASK]\n",
    "\n",
    "    def get_history_as_json(self):\n",
    "        # returns browser history as list of json documents\n",
    "        self.cursor.execute(\"\"\"\n",
    "            SELECT urls.id,\n",
    "                   urls.url, \n",
    "                   urls.title, \n",
    "                   urls.visit_count, \n",
    "                   urls.typed_count, \n",
    "                   DATETIME(urls.last_visit_time / 1000000 + (strftime('%s', '1601-01-01')), 'unixepoch', 'localtime') as last_visit_date, \n",
    "                   DATETIME(visit_time / 1000000 + (strftime('%s', '1601-01-01')), 'unixepoch', 'localtime') as visit_date, \n",
    "                   visits.from_visit, \n",
    "                   visits.transition as visit_type,\n",
    "                   'Chrome' as browser\n",
    "            FROM urls, visits\n",
    "            WHERE urls.id = visits.url\n",
    "        \"\"\")\n",
    "        rows_as_json = self._to_json(self.cursor)\n",
    "        return rows_as_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19f8b54",
   "metadata": {},
   "source": [
    "#### Extract browsers' history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b2993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Aggregator() as agg:\n",
    "    db_files = agg.db_files\n",
    "    for browser, AggregatorBrowser in list(zip(db_files, [AggregatorChrome, AggregatorFirefox])):\n",
    "        db_file = db_files[browser]['tmp']\n",
    "        print(f'\\n{browser}: ', db_file, end=\"\\n\\n\")\n",
    "        try:\n",
    "            agg_browser = AggregatorBrowser(db_file) \n",
    "            tables = agg_browser._get_history_tables(agg_browser.conn, agg_browser.cursor)\n",
    "\n",
    "            for table in tables:\n",
    "                fields = agg_browser._get_fields(table)\n",
    "                print(table, fields, sep = \"\\n\", end = \"\\n\\n\")\n",
    "\n",
    "            json_docs = agg_browser.get_history_as_json()\n",
    "            # print(json_docs)\n",
    "            agg.merge(json_docs)\n",
    "        except sqlite3.OperationalError as e:\n",
    "            print(str(e))\n",
    "    \n",
    "    print(json.dumps(agg.browsing_history, indent = 2))\n",
    "    \n",
    "    agg.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17610c3a",
   "metadata": {},
   "source": [
    "## Build a search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e659483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch as es\n",
    "import elasticsearch.helpers as helpers\n",
    "from uuid import uuid4\n",
    "from datetime import datetime as dt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86940351",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class SearchEngine:\n",
    "    def __init__(self, host):\n",
    "        self.client = es.Elasticsearch(host)\n",
    "        ping = self.client.ping()\n",
    "        if not ping:\n",
    "            raise Exception('Error: could not connect to cluster')\n",
    "        print('Ok: cluster is up')\n",
    "    \n",
    "    def cluster_info(self):\n",
    "        print(json.dumps(self.client.info(), indent = 2))\n",
    "    \n",
    "    def create_index(self, index_name, sim_module, mappings):\n",
    "        request_body = {\n",
    "            'settings': {\n",
    "                'number_of_shards': 1,\n",
    "                'number_of_replicas': 1,\n",
    "                'similarity' : sim_module\n",
    "            }\n",
    "        }\n",
    "        request_body.update(mappings)\n",
    "        print(request_body)\n",
    "        if self.client.indices.exists(index_name):\n",
    "            raise Exception(f'Error: index {index_name} exists.')\n",
    "        self.client.indices.create(index_name, body = request_body, ignore = 400)\n",
    "        print(f'OK: index {index_name} created.')\n",
    "        \n",
    "    def do_index(self, docs, _index, _doc):\n",
    "        def bulk(docs, _index, _doc):\n",
    "            for i, doc in enumerate(docs):\n",
    "                action = {\n",
    "                    \"_index\": _index,\n",
    "                    \"_doc\": _doc,\n",
    "                    \"_id\": i,\n",
    "                    \"_source\": {\n",
    "                        key : value \n",
    "                        for key, value in doc.items()\n",
    "                    }\n",
    "                }\n",
    "                yield action\n",
    "        \n",
    "        try:\n",
    "            res = helpers.bulk(self.client, bulk(docs, _index, _doc))\n",
    "            succ, fail = res\n",
    "            print(f'Ok: success: {succ}; fail: {fail}')\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    \n",
    "    def update_ranking_model(self, index_name, sim_module):\n",
    "        name = [*sim_module.keys()][0]\n",
    "        settings = { \n",
    "            'settings' : {\n",
    "                'index' : {\n",
    "                    'similarity' : sim_module\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.client.indices.close(index = index_name)\n",
    "        self.client.indices.put_settings(index = index_name, body = settings)\n",
    "        self.client.indices.open(index = index_name)\n",
    "        \n",
    "        model_type = sim_module[name]['type'].lower()\n",
    "        base_index_name = index_name.split('_')[-1]\n",
    "        new_index_name = f'{model_type}_{base_index_name}'\n",
    "                \n",
    "        if self._re_index(index_name, new_index_name):\n",
    "            # delete old index\n",
    "            self.client.indices.delete(index = index_name)\n",
    "            if self._update_alias(new_index_name, base_index_name):                \n",
    "                print(f\"Index {index_name} updated with ranking model {model_type}\")\n",
    "        else:\n",
    "            print(f\"Failed to update {index_name} with ranking model {model_type}\")\n",
    "    \n",
    "    def _re_index(self, index_name, new_index_name):\n",
    "        # reindexes the old index with a new name\n",
    "        res = self.client.reindex({\n",
    "            'source' : {\n",
    "                'index' : index_name\n",
    "            },\n",
    "            'dest' : {\n",
    "                'index' : new_index_name\n",
    "            }\n",
    "        })['total'] > 0\n",
    "        return res\n",
    "    \n",
    "    def _update_alias(self, index_name, alias):\n",
    "        # creates alias with old index name to new index name\n",
    "        # so we can keep using the old index name\n",
    "        # e.g., history -> dfr_history\n",
    "        res = bool(self.client.indices.update_aliases(body = {\n",
    "            'actions' : [{\n",
    "                'add'  : {\n",
    "                    'index' : index_name,\n",
    "                    'alias' : alias\n",
    "                }\n",
    "            }]\n",
    "        })['acknowledged'])\n",
    "        return res\n",
    "    \n",
    "    def index_info(self, index_name = None):\n",
    "        if index_name:\n",
    "            info = json.dumps(self.client.cat.indices(format = 'json', index = index_name), indent = 2)\n",
    "        else:\n",
    "            info = json.dumps(self.client.cat.indices(format = 'json'), indent = 2)\n",
    "        print(info)\n",
    "            \n",
    "    def _convert_to_date(self, field):\n",
    "        try:\n",
    "            date = dt.strptime(field, '%Y-%m-%d %H:%M:%S')\n",
    "            return date\n",
    "        except:\n",
    "            return field\n",
    "            \n",
    "    def extract_mappings(self, sample):\n",
    "        sample_ = sample.copy()\n",
    "        sanitised_vals = [*map(self._convert_to_date, list(sample_.values()))]\n",
    "        sample_.update(\n",
    "            (field, val) \n",
    "            for field, val in zip(\n",
    "                sample_.keys(), sanitised_vals\n",
    "            )\n",
    "        )   \n",
    "        print(sample_)\n",
    "        types = {\n",
    "            'int'      : 'integer',\n",
    "            'str'      : 'text',\n",
    "            'datetime' : 'date'\n",
    "        }\n",
    "        return {\n",
    "            'mapping' : {\n",
    "                '_source' : {\n",
    "                    'enabled' : 'true'\n",
    "                },\n",
    "                'properties' : {\n",
    "                    property_ : { \n",
    "                        'type' : types[type(property_val).__name__] \n",
    "                    }\n",
    "                    for property_, property_val in sample_.items()\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def query(self, index, body = {\"query\": {\"match_all\": {}}}):\n",
    "        return self.client.search(body = body, index = index, explain = True)\n",
    "    \n",
    "    def get_hits(self, results, *fields, explain = True, fmt = 'json'):\n",
    "        if fmt == 'json':\n",
    "            return {\n",
    "                'count' : results['hits']['total']['value'],\n",
    "                'hits' : {\n",
    "                    hit['_id'] : {\n",
    "                        **({ field : hit['_source'][field] for field in fields}),\n",
    "                        'score': hit['_score'],\n",
    "                        **({ 'explanation' : hit['_explanation'] } if explain else {})\n",
    "                    } \n",
    "                    for hit in results['hits']['hits']\n",
    "                }\n",
    "            }\n",
    "        elif fmt == 'ascii':\n",
    "            fmt_hits = []\n",
    "            for hit in res['hits']['hits']:\n",
    "                fmt_str = f\"id: {hit['_id']}\\n\"\n",
    "                for field in fields:\n",
    "                    fmt_str += f\"{field}: {hit['_source'][field]}\\n\"\n",
    "                fmt_str += f\"score: {hit['_score']}\\n\"\n",
    "                fmt_hits.append(fmt_str)\n",
    "            return '\\n'.join(fmt_hits)\n",
    "        else:\n",
    "            raise ValueError(f'Error: unrecognised format {fmt}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4495a5a2",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of docs: 37\n"
     ]
    }
   ],
   "source": [
    "# mocks dataset from aggregator\n",
    "docs = json.loads(\"\"\"\n",
    "[\n",
    "  {\n",
    "    \"id\": 12181,\n",
    "    \"url\": \"https://www.google.com/search?q=sqlite+chrome+history&oq=sqlite+chrome+&aqs=chrome.3.69i57j0i512l3j0i22i30l6.3022j0j4&sourceid=chrome&ie=UTF-8\",\n",
    "    \"title\": \"sqlite chrome history - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:50:14\",\n",
    "    \"visit_date\": \"2023-03-19 21:50:13\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"generated\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12181,\n",
    "    \"url\": \"https://www.google.com/search?q=sqlite+chrome+history&oq=sqlite+chrome+&aqs=chrome.3.69i57j0i512l3j0i22i30l6.3022j0j4&sourceid=chrome&ie=UTF-8\",\n",
    "    \"title\": \"sqlite chrome history - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:50:14\",\n",
    "    \"visit_date\": \"2023-03-19 21:50:14\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12182,\n",
    "    \"url\": \"https://en.wikiversity.org/wiki/Chromium_browsing_history_database\",\n",
    "    \"title\": \"Chromium browsing history database - Wikiversity\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:50:26\",\n",
    "    \"visit_date\": \"2023-03-19 21:50:26\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12183,\n",
    "    \"url\": \"https://www.researchgate.net/figure/Chrome-history-SQLite-The-highlighted-record-corresponds-to-a-bookmark-added-in-the_fig1_262880203\",\n",
    "    \"title\": \"Chrome history SQLite. The highlighted record corresponds to a bookmark... | Download Scientific Diagram\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:50:27\",\n",
    "    \"visit_date\": \"2023-03-19 21:50:27\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12191,\n",
    "    \"url\": \"https://github.com/tomasraposo/ir-search-engine/blob/714f37b9808718ebae220c8f64e7e83070d0117e/src/aggregator.ipynb\",\n",
    "    \"title\": \"ir-search-engine/aggregator.ipynb at 714f37b9808718ebae220c8f64e7e83070d0117e \\u00b7 tomasraposo/ir-search-engine\",\n",
    "    \"visit_count\": 3,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 22:19:42\",\n",
    "    \"visit_date\": \"2023-03-19 21:55:12\",\n",
    "    \"from_visit\": 25,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12191,\n",
    "    \"url\": \"https://github.com/tomasraposo/ir-search-engine/blob/714f37b9808718ebae220c8f64e7e83070d0117e/src/aggregator.ipynb\",\n",
    "    \"title\": \"ir-search-engine/aggregator.ipynb at 714f37b9808718ebae220c8f64e7e83070d0117e \\u00b7 tomasraposo/ir-search-engine\",\n",
    "    \"visit_count\": 3,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 22:19:42\",\n",
    "    \"visit_date\": \"2023-03-19 21:55:12\",\n",
    "    \"from_visit\": 27,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12192,\n",
    "    \"url\": \"https://www.google.com/search?q=firefox+host&oq=firefox+host&aqs=chrome..69i57j0i512l7j0i22i30l2.3143j0j7&sourceid=chrome&ie=UTF-8\",\n",
    "    \"title\": \"firefox host - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:57:08\",\n",
    "    \"visit_date\": \"2023-03-19 21:57:07\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"generated\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12192,\n",
    "    \"url\": \"https://www.google.com/search?q=firefox+host&oq=firefox+host&aqs=chrome..69i57j0i512l7j0i22i30l2.3143j0j7&sourceid=chrome&ie=UTF-8\",\n",
    "    \"title\": \"firefox host - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:57:08\",\n",
    "    \"visit_date\": \"2023-03-19 21:57:08\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12194,\n",
    "    \"url\": \"https://www.google.com/search?q=firefox+sqlite+datbase+schema&oq=firefox+sqlite+datbase+schema&aqs=chrome..69i57j33i10i160j33i10i22i29i30l5j33i10i15i22i29i30.4066j0j7&sourceid=chrome&ie=UTF-8\",\n",
    "    \"title\": \"firefox sqlite datbase schema - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:57:51\",\n",
    "    \"visit_date\": \"2023-03-19 21:57:50\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"generated\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12194,\n",
    "    \"url\": \"https://www.google.com/search?q=firefox+sqlite+datbase+schema&oq=firefox+sqlite+datbase+schema&aqs=chrome..69i57j33i10i160j33i10i22i29i30l5j33i10i15i22i29i30.4066j0j7&sourceid=chrome&ie=UTF-8\",\n",
    "    \"title\": \"firefox sqlite datbase schema - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:57:51\",\n",
    "    \"visit_date\": \"2023-03-19 21:57:51\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12195,\n",
    "    \"url\": \"https://wiki.mozilla.org/File:Places.sqlite.schema.pdf\",\n",
    "    \"title\": \"File:Places.sqlite.schema.pdf - MozillaWiki\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:58:21\",\n",
    "    \"visit_date\": \"2023-03-19 21:57:54\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12196,\n",
    "    \"url\": \"https://mozilla.github.io/firefox-browser-architecture/text/0010-firefox-data-stores.html\",\n",
    "    \"title\": \"Firefox Data Stores\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:58:02\",\n",
    "    \"visit_date\": \"2023-03-19 21:58:02\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12197,\n",
    "    \"url\": \"https://www.google.com/search?q=firefox+sqlite+history+schemas&ei=XoUXZNfqO-P0qwHF5pSQDw&ved=0ahUKEwjXkdK2_uj9AhVj-ioKHUUzBfIQ4dUDCA8&uact=5&oq=firefox+sqlite+history+schemas&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIICCEQoAEQwwQyCAghEKABEMMEMggIIRCgARDDBDoICAAQhgMQsAM6BAgAEB46BggAEAgQHjoFCAAQhgM6CgghEKABEMMEEApKBAhBGAFQxQJYwhZg0BdoAXAAeACAAb0CiAGvC5IBBzAuNi4xLjGYAQCgAQHIAQTAAQE&sclient=gws-wiz-serp\",\n",
    "    \"title\": \"firefox sqlite history schemas - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:58:21\",\n",
    "    \"visit_date\": \"2023-03-19 21:58:20\",\n",
    "    \"from_visit\": 34,\n",
    "    \"visit_type\": \"submit\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12197,\n",
    "    \"url\": \"https://www.google.com/search?q=firefox+sqlite+history+schemas&ei=XoUXZNfqO-P0qwHF5pSQDw&ved=0ahUKEwjXkdK2_uj9AhVj-ioKHUUzBfIQ4dUDCA8&uact=5&oq=firefox+sqlite+history+schemas&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIICCEQoAEQwwQyCAghEKABEMMEMggIIRCgARDDBDoICAAQhgMQsAM6BAgAEB46BggAEAgQHjoFCAAQhgM6CgghEKABEMMEEApKBAhBGAFQxQJYwhZg0BdoAXAAeACAAb0CiAGvC5IBBzAuNi4xLjGYAQCgAQHIAQTAAQE&sclient=gws-wiz-serp\",\n",
    "    \"title\": \"firefox sqlite history schemas - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:58:21\",\n",
    "    \"visit_date\": \"2023-03-19 21:58:21\",\n",
    "    \"from_visit\": 37,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12195,\n",
    "    \"url\": \"https://wiki.mozilla.org/File:Places.sqlite.schema.pdf\",\n",
    "    \"title\": \"File:Places.sqlite.schema.pdf - MozillaWiki\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:58:21\",\n",
    "    \"visit_date\": \"2023-03-19 21:58:21\",\n",
    "    \"from_visit\": 38,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12198,\n",
    "    \"url\": \"https://wiki.mozilla.org/images/0/08/Places.sqlite.schema.pdf\",\n",
    "    \"title\": \"Places.sqlite.schema.pdf\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 21:58:24\",\n",
    "    \"visit_date\": \"2023-03-19 21:58:24\",\n",
    "    \"from_visit\": 39,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12199,\n",
    "    \"url\": \"https://www.google.com/search?q=moz_places_metadata&oq=moz_places_metadata&aqs=chrome..69i57.4730j0j7&sourceid=chrome&ie=UTF-8\",\n",
    "    \"title\": \"moz_places_metadata - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 22:04:02\",\n",
    "    \"visit_date\": \"2023-03-19 22:04:01\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"generated\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12199,\n",
    "    \"url\": \"https://www.google.com/search?q=moz_places_metadata&oq=moz_places_metadata&aqs=chrome..69i57.4730j0j7&sourceid=chrome&ie=UTF-8\",\n",
    "    \"title\": \"moz_places_metadata - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 22:04:02\",\n",
    "    \"visit_date\": \"2023-03-19 22:04:02\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12200,\n",
    "    \"url\": \"https://raw.githubusercontent.com/mozilla/gecko-dev/master/toolkit/components/places/nsPlacesIndexes.h\",\n",
    "    \"title\": \"\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 22:04:14\",\n",
    "    \"visit_date\": \"2023-03-19 22:04:14\",\n",
    "    \"from_visit\": 42,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12201,\n",
    "    \"url\": \"https://www.google.com/search?q=moz_places_metadata&oq=moz_places_metadata&aqs=chrome.0.69i59.2125j0j7&sourceid=chrome&ie=UTF-8\",\n",
    "    \"title\": \"moz_places_metadata - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 22:05:04\",\n",
    "    \"visit_date\": \"2023-03-19 22:05:04\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"generated\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12201,\n",
    "    \"url\": \"https://www.google.com/search?q=moz_places_metadata&oq=moz_places_metadata&aqs=chrome.0.69i59.2125j0j7&sourceid=chrome&ie=UTF-8\",\n",
    "    \"title\": \"moz_places_metadata - Google Search\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 22:05:04\",\n",
    "    \"visit_date\": \"2023-03-19 22:05:04\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12191,\n",
    "    \"url\": \"https://github.com/tomasraposo/ir-search-engine/blob/714f37b9808718ebae220c8f64e7e83070d0117e/src/aggregator.ipynb\",\n",
    "    \"title\": \"ir-search-engine/aggregator.ipynb at 714f37b9808718ebae220c8f64e7e83070d0117e \\u00b7 tomasraposo/ir-search-engine\",\n",
    "    \"visit_count\": 3,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 22:19:42\",\n",
    "    \"visit_date\": \"2023-03-19 22:19:42\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12216,\n",
    "    \"url\": \"https://github.com/tomasraposo/ir-search-engine\",\n",
    "    \"title\": \"tomasraposo/ir-search-engine\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 22:19:44\",\n",
    "    \"visit_date\": \"2023-03-19 22:19:44\",\n",
    "    \"from_visit\": 69,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12217,\n",
    "    \"url\": \"https://github.com/tomasraposo/ir-search-engine/tree/aggregator\",\n",
    "    \"title\": \"tomasraposo/ir-search-engine at aggregator\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": 0,\n",
    "    \"last_visit_date\": \"2023-03-19 22:20:08\",\n",
    "    \"visit_date\": \"2023-03-19 22:20:08\",\n",
    "    \"from_visit\": 70,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Chrome\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 1,\n",
    "    \"url\": \"https://www.google.com/search?channel=fs&client=ubuntu&q=mozilla+sqlite+schemas+\",\n",
    "    \"title\": \"mozilla sqlite schemas - Google Search\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:18:51\",\n",
    "    \"visit_date\": \"2023-03-19 21:18:51\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"typed\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 2,\n",
    "    \"url\": \"https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjus4rb9ej9AhUKt4sKHQ91AZUQFnoECA0QAQ&url=https%3A%2F%2Fwiki.mozilla.org%2Fimages%2F0%2F08%2FPlaces.sqlite.schema.pdf&usg=AOvVaw1VqHh-NQHUFYqoK6-DldIH\",\n",
    "    \"title\": null,\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:18:55\",\n",
    "    \"visit_date\": \"2023-03-19 21:18:55\",\n",
    "    \"from_visit\": 1,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 3,\n",
    "    \"url\": \"https://wiki.mozilla.org/images/0/08/Places.sqlite.schema.pdf\",\n",
    "    \"title\": \"Places.sqlite.schema.pdf\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:18:56\",\n",
    "    \"visit_date\": \"2023-03-19 21:18:56\",\n",
    "    \"from_visit\": 2,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 4,\n",
    "    \"url\": \"https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjus4rb9ej9AhUKt4sKHQ91AZUQFnoECA4QAQ&url=https%3A%2F%2Fwiki.mozilla.org%2Fimages%2F7%2F72%2FContent-prefs.sqlite.schema.pdf&usg=AOvVaw2xp8uTcWWZhEur4dMUmp4v\",\n",
    "    \"title\": null,\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:18:59\",\n",
    "    \"visit_date\": \"2023-03-19 21:18:59\",\n",
    "    \"from_visit\": 1,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 5,\n",
    "    \"url\": \"https://wiki.mozilla.org/images/7/72/Content-prefs.sqlite.schema.pdf\",\n",
    "    \"title\": \"Content-prefs.sqlite.schema.pdf\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:19:01\",\n",
    "    \"visit_date\": \"2023-03-19 21:19:01\",\n",
    "    \"from_visit\": 4,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 6,\n",
    "    \"url\": \"https://www.google.com/search?q=sqlite+documentation&client=ubuntu&hs=qFP&channel=fs&ei=O3wXZK6qHYrurgSP6oWoCQ&ved=0ahUKEwjus4rb9ej9AhUKt4sKHQ91AZUQ4dUDCGo&uact=5&oq=sqlite+documentation&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIGCAAQFhAeMgYIABAWEB4yBggAEBYQHjIGCAAQFhAeOgoIABBHENYEELADOgQIABBDOgUIABCRAjoLCC4QgAQQxwEQ0QM6BQgAEIYDSgQIQRgAUJsJWPcXYPYaaANwAXgAgAGVAYgB-BCSAQQ1LjE1mAEAoAEByAECwAEB&sclient=gws-wiz-serp\",\n",
    "    \"title\": \"sqlite documentation - Google Search\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:19:07\",\n",
    "    \"visit_date\": \"2023-03-19 21:19:07\",\n",
    "    \"from_visit\": 1,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 7,\n",
    "    \"url\": \"file:///home/tomasraposo/.local/share/jupyter/runtime/nbserver-962520-open.html\",\n",
    "    \"title\": \"Opening Jupyter Notebook\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:19:11\",\n",
    "    \"visit_date\": \"2023-03-19 21:19:11\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 8,\n",
    "    \"url\": \"http://localhost:8888/tree?token=1de4774f1cd881f1ed29059dd80fc03ec3f54e40761b2f0c\",\n",
    "    \"title\": \"Home Page - Select or create a notebook\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:19:12\",\n",
    "    \"visit_date\": \"2023-03-19 21:19:12\",\n",
    "    \"from_visit\": 7,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 9,\n",
    "    \"url\": \"http://localhost:8888/tree\",\n",
    "    \"title\": \"Home Page - Select or create a notebook\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:19:12\",\n",
    "    \"visit_date\": \"2023-03-19 21:19:12\",\n",
    "    \"from_visit\": 8,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 10,\n",
    "    \"url\": \"http://localhost:8888/notebooks/aggregator.ipynb\",\n",
    "    \"title\": \"aggregator - Jupyter Notebook\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:19:26\",\n",
    "    \"visit_date\": \"2023-03-19 21:19:26\",\n",
    "    \"from_visit\": 9,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 11,\n",
    "    \"url\": \"http://localhost:8888/notebooks/aggregator.ipynb#\",\n",
    "    \"title\": \"aggregator - Jupyter Notebook\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:27:19\",\n",
    "    \"visit_date\": \"2023-03-19 21:20:25\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 14,\n",
    "    \"url\": \"http://localhost:8888/notebooks/aggregator.ipynb#\",\n",
    "    \"title\": \"aggregator - Jupyter Notebook\",\n",
    "    \"visit_count\": 2,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:27:19\",\n",
    "    \"visit_date\": \"2023-03-19 21:27:19\",\n",
    "    \"from_visit\": 0,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 15,\n",
    "    \"url\": \"http://localhost:8888/notebooks/Untitled1.ipynb?kernel_name=python3\",\n",
    "    \"title\": \"Untitled1 - Jupyter Notebook\",\n",
    "    \"visit_count\": 1,\n",
    "    \"typed_count\": \"0\",\n",
    "    \"last_visit_date\": \"2023-03-19 21:27:20\",\n",
    "    \"visit_date\": \"2023-03-19 21:27:20\",\n",
    "    \"from_visit\": 14,\n",
    "    \"visit_type\": \"link\",\n",
    "    \"browser\": \"Firefox\"\n",
    "  }\n",
    "]\n",
    "\"\"\")\n",
    "print(f'Total number of docs: {len(docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db2c769",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok: cluster is up\n"
     ]
    }
   ],
   "source": [
    "# instantiate the search engine\n",
    "try:\n",
    "    se = SearchEngine(host)\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# se.cluster_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdef26b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can manually delete an index or all - * - if you feel you messed somewhere\n",
    "se.client.indices.delete(index = '*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a781c",
   "metadata": {},
   "source": [
    "## Ranking models\n",
    "_BM25 similarity (default)_\n",
    "\n",
    "Note: we're required to explain how ranking works for each of the models used, i.e. how it reflects in the documents returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ab3ad",
   "metadata": {},
   "source": [
    "### BM25 (Best Match Okapi)\n",
    "This is the default ranking model used by Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e98a9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_bm25  = {\n",
    "    'sim_bm25' : {\n",
    "        'type' : 'BM25',\n",
    "        'b' : '0.75',\n",
    "        'k1' : 1.2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e35cd45",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 12181, 'url': 'https://www.google.com/search?q=sqlite+chrome+history&oq=sqlite+chrome+&aqs=chrome.3.69i57j0i512l3j0i22i30l6.3022j0j4&sourceid=chrome&ie=UTF-8', 'title': 'sqlite chrome history - Google Search', 'visit_count': 2, 'typed_count': 0, 'last_visit_date': datetime.datetime(2023, 3, 19, 21, 50, 14), 'visit_date': datetime.datetime(2023, 3, 19, 21, 50, 13), 'from_visit': 0, 'visit_type': 'generated', 'browser': 'Chrome'}\n",
      "{'settings': {'number_of_shards': 1, 'number_of_replicas': 1, 'similarity': {'sim_bm25': {'type': 'BM25', 'b': '0.75', 'k1': 1.2}}}, 'mapping': {'_source': {'enabled': 'true'}, 'properties': {'id': {'type': 'integer'}, 'url': {'type': 'text'}, 'title': {'type': 'text'}, 'visit_count': {'type': 'integer'}, 'typed_count': {'type': 'integer'}, 'last_visit_date': {'type': 'date'}, 'visit_date': {'type': 'date'}, 'from_visit': {'type': 'integer'}, 'visit_type': {'type': 'text'}, 'browser': {'type': 'text'}}}}\n",
      "OK: index history created.\n",
      "Ok: success: 37; fail: []\n",
      "[\n",
      "  {\n",
      "    \"health\": \"yellow\",\n",
      "    \"status\": \"open\",\n",
      "    \"index\": \"history\",\n",
      "    \"uuid\": \"dS2zw4KPRoqbjVw0j_TD4A\",\n",
      "    \"pri\": \"1\",\n",
      "    \"rep\": \"1\",\n",
      "    \"docs.count\": \"0\",\n",
      "    \"docs.deleted\": \"0\",\n",
      "    \"store.size\": \"208b\",\n",
      "    \"pri.store.size\": \"208b\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# get document sample\n",
    "sample_doc = docs[0]\n",
    "        \n",
    "# extract mappings from document sample\n",
    "mappings = se.extract_mappings(sample_doc)\n",
    "\n",
    "# create index\n",
    "index_name = 'history'\n",
    "_doc = 'browser_history'\n",
    "try:\n",
    "    se.create_index(index_name, sim_bm25, mappings)\n",
    "    # bulk index docs\n",
    "    se.do_index(docs, index_name, _doc)        \n",
    "except:\n",
    "    pass\n",
    "\n",
    "se.index_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac066f2",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "NotFoundError(404, 'index_not_found_exception', 'no such index [history]', history, index_or_alias)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-47af884b6ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get all records\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-292f1e0c9cbf>\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, index, body)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"match_all\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_hits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/client/utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/client/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, body, index, doc_type, params, headers)\u001b[0m\n\u001b[1;32m   1610\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"from\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         return self.transport.perform_request(\n\u001b[0m\u001b[1;32m   1613\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0m_make_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_search\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    390\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 status, headers_response, data = connection.perform_request(\n\u001b[0m\u001b[1;32m    359\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             )\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         self.log_request_success(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/connection/base.py\u001b[0m in \u001b[0;36m_raise_error\u001b[0;34m(self, status_code, raw_data)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Undecodable raw error response from server: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         raise HTTP_EXCEPTIONS.get(status_code, TransportError)(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: NotFoundError(404, 'index_not_found_exception', 'no such index [history]', history, index_or_alias)"
     ]
    }
   ],
   "source": [
    "# get all records\n",
    "q = se.query(index_name)\n",
    "print(json.dumps(q, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0104169",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# search for `sqlite` in  title\n",
    "query = {\n",
    "    'query' : {\n",
    "        'term'  : {\n",
    "            'title' : 'sqlite'\n",
    "        } \n",
    "    } \n",
    "}\n",
    "\n",
    "\n",
    "res = se.query(index_name, body = query)\n",
    "hits = se.get_hits(res, *['url', 'title', 'visit_date', 'last_visit_date'], explain = False, fmt = 'ascii')\n",
    "# if you want to print as json use `json.dumps(hits, indent = 2)`\n",
    "print(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce127d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bool clause allows us to build boolean expressions\n",
    "# `should` behaves like an OR clause whereas `must` behaves like an AND clause\n",
    "# this can be used across many fields\n",
    "\n",
    "# search for either keyword in title\n",
    "keywords = 'sqlite documentation history'\n",
    "query = {\n",
    "    'query' : {\n",
    "        'bool' : {\n",
    "            'should' : [\n",
    "                {\n",
    "                    'terms' : {\n",
    "                        'title' : keywords.split(' ')\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "res = se.query(index_name, body = query)\n",
    "hits = se.get_hits(res, *['url', 'title', 'visit_date', 'last_visit_date'], explain = False)\n",
    "print(json.dumps(hits, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36cb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for documents whose `last_visit_date` is more recent than March 29 and contain\n",
    "# either history on the `title` or google somewhere in the URL\n",
    "# note: /google/ is a regex pattern.\n",
    "query = {\n",
    "    'query' : {\n",
    "        'bool' : {\n",
    "            'must' : [\n",
    "                {\n",
    "                    'range' : {\n",
    "                        'last_visit_date' : {\n",
    "                            'gte' : '2023-29-03'\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            'should' : [\n",
    "                {\n",
    "                    'match'  : { \n",
    "                        'title' : 'history'\n",
    "                    },\n",
    "                    'match' : {\n",
    "                        'url' :  '/google/'\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "res = se.query(index_name, body = query)\n",
    "hits = se.get_hits(res, *['url', 'title', 'visit_date', 'last_visit_date'], explain = False)\n",
    "print(json.dumps(hits, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9fd872",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'query': {\n",
    "        'range': {\n",
    "            'last_visit_date' : {\n",
    "#                 \"gte\": \"2023-01-01 00:00:00\",\n",
    "                \"lte\": \"2023-03-18 00:00:00\",\n",
    "                \"format\": \"yyyy-MM-dd HH-mm-ss\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "res = se.query(index_name, body = query)\n",
    "hits = se.get_hits(res, *['url', 'title', 'visit_date', 'last_visit_date'], explain = False)\n",
    "print(json.dumps(hits, indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dbb1fd",
   "metadata": {},
   "source": [
    "### DFR (Divergence from Randomness)\n",
    "This model takes into account statistical properties of the collection, e.g. frequency and distribution of terms within the collection, length of documents, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dfr = {\n",
    "    \"sim_dfr\": {\n",
    "      \"type\": \"DFR\",\n",
    "      \"basic_model\": \"g\",\n",
    "      \"after_effect\": \"l\",\n",
    "      \"normalization\": \"h2\",\n",
    "      \"normalization.h2.c\": \"2.0\"\n",
    "    }\n",
    "}\n",
    "se.update_ranking_model(index_name, sim_dfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b722f79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "se.index_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ccfd7",
   "metadata": {},
   "source": [
    "### BM25F\n",
    "This can be achieved using a `multi_match` query, which allows us to assign different weights to each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ebca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_bm25f = {\n",
    "    \"sim_bm25f\": {\n",
    "        'type' : 'BM25',\n",
    "        'b' : '0.75',\n",
    "        'k1' : 1.2\n",
    "    }\n",
    "}\n",
    "# we have to update using the actual index name not the alias\n",
    "# this is a known issue in Elasticsearch\n",
    "# you can check the index name with `se.index_info()` in the cell above\n",
    "se.update_ranking_model(f'{index_name}', sim_bm25f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371edb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "se.index_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign weights to fields\n",
    "fields = [\n",
    "    f'{field}^{str(weight)}' for field, weight in zip(\n",
    "        ['title', 'url', 'browser', 'last_visit_date'], \n",
    "        [1, 2, 3, 4]\n",
    "    )\n",
    "]\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f786f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# `combined_fields` was introduced in v7.13 and truly implements BM25F\n",
    "# as we running an old version (as provided by the lecturer), \n",
    "# we have to either use `multi_match` or bump the version (not sure we can)\n",
    "# see: https://opensourceconnections.com/blog/2021/06/30/better-term-centric-scoring-in-elasticsearch-with-bm25f-and-the-combined_fields-query/\n",
    "\n",
    "query = {\n",
    "    'query' : {\n",
    "        'multi_match' : {\n",
    "            'query' : 'sqlite',\n",
    "            'fields' : fields,\n",
    "            'type' : 'cross_fields'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "q1 = se.query(index_name, body = query)\n",
    "hits = se.get_hits(q1, *['url', 'title', 'visit_date', 'last_visit_date'], explain = False)\n",
    "print(json.dumps(hits, indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19810ac5",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01347a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates how well documents match a given query. \n",
    "\n",
    "# The test suite contains 3-tuples of the form query id, document id and score. \n",
    "# They are used to calculate the average effectiveness of the search engine by\n",
    "# calculating the recall and precision values for each query.\n",
    "\n",
    "# Subsequently the F-score of the function will be calculated. \n",
    "\n",
    "# Given these characteristics, we will also calculate the fall-out to understand \n",
    "# the probability of a non-relevant document being retrieved by the function.\n",
    "\n",
    "# The relevance judgments are prepared as a single suite for all queries under testing\n",
    "\n",
    "# BM25 or BM25F is going to be the ranking model we use\n",
    "\n",
    "# Query 1:\n",
    "# search for `sqlite` in  title\n",
    "query1 = {\n",
    "    'query' : {\n",
    "        'term'  : {\n",
    "            'title' : 'sqlite'\n",
    "        } \n",
    "    } \n",
    "}\n",
    "\n",
    "res = se.query(index_name, body = query1)\n",
    "hits = se.get_hits(res, *['url', 'title', 'visit_date', 'last_visit_date'], explain = False, fmt = 'ascii')\n",
    "print(hits)\n",
    "\n",
    "# prepare relevance judgments\n",
    "q1_rj = [\n",
    "    (0, doc_id, score) \n",
    "    for doc_id, score in zip(\n",
    "        range(37),\n",
    "        [2,3,0,0,0,0,0,0,2,3,1,0,0,0,0,0]\n",
    "    )\n",
    "]\n",
    "\n",
    "# calculate recall, precision, F-score, fall out\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46e3328",
   "metadata": {},
   "source": [
    "### User Interface"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
